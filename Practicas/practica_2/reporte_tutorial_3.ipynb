{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporte Practica 2: Procesamiento de datos <br />Carlos Espinoza - B92786"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong>Que son los`Outliers`</strong>\n",
    "\n",
    "Un outlier es una obervación que se distingue mucho de otras observaciones. Generalmente se definen como obervaciones que están excepcionalmente lejos de la línea de observaciones dentro de los datos.\n",
    "\n",
    "No hay una forma precisa de detectar e identificar los outliers, pues estos son muy específicos del dataset con el que estemos trabajando.\n",
    "\n",
    "### Probar el dataset\n",
    "\n",
    "Para esta prueba se generarán 10K números aleatorios bajo ciertas condiciones. Se va a utilizar una semilla para asegurarnos que siempre vamos a obtener los mismos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=50.049 stdv=4.994\n"
     ]
    }
   ],
   "source": [
    "# generate gaussian data\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# summarize\n",
    "print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de la desviación estándar\n",
    "\n",
    "La distribución gausseana tiene la propiedad de que la desviación de la media puede usarse para obtener un resumen confiable de la muestra. Por ejemplo con una desviación estándar de la media se puede cubrir un 68% de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified outliers: 29\n",
      "Non-outlier observations: 9971\n"
     ]
    }
   ],
   "source": [
    "# identify outliers with standard deviation\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# calculate summary statistics\n",
    "data_mean, data_std = mean(data), std(data)\n",
    "# identify outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de rango intercuartílico\n",
    "\n",
    "No todos los datos se encuentran normalizados o lo suficientemente normalizados para ser tratados como una distribución gausseana. Una buena medida estadística para medir las distribuciones en estos tipos de muetras es el rango intercuartílico.\n",
    "\n",
    "Este rango se calcula mediante la diferencia de los percentiles 75 y 25. El rango define el 50% del medio de los datos, o lo que también se llama `el cuerpo de los datos`.\n",
    "\n",
    "Para hacer estos cálculos podemos hacer uso del módulo Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: 25th=46.685, 75th=53.359, IQR=6.674\n",
      "Identified outliers: 81\n",
      "Non-outlier observations: 9919\n"
     ]
    }
   ],
   "source": [
    "# identify outliers with interquartile range\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# calculate interquartile range\n",
    "q25, q75 = percentile(data, 25), percentile(data, 75)\n",
    "iqr = q75 - q25\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección automática de Outliers\n",
    "\n",
    "En aprendizaje de máquina se utiliza `one-class classification` para atacar el problema de la detección de outliers.\n",
    "\n",
    "`One-class classification` acomoda un modelo en los datos 'normalizados' y predice si las nuevas entradas son normales, outliers o anomalías.\n",
    "\n",
    "Este clasificador se base en un dataset de entrenamiento que contiene únicamente datos normalizados, una vez que este esté cargado en el modelo es que se pueden tomar decisiones respecto a las nuevas entradas. \n",
    "\n",
    "Se probará con datos de `Boston Housing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "(339, 13) (167, 13) (339,) (167,)\n"
     ]
    }
   ],
   "source": [
    "# load and summarize the dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "df = read_csv(url, header=None)\n",
    "# retrieve the array\n",
    "data = df.values\n",
    "# split into inpiut and output elements\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# summarize the shape of the dataset\n",
    "print(X.shape, y.shape)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize the shape of the train and test sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.417\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on the raw dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "df = read_csv(url, header=None)\n",
    "# retrieve the array\n",
    "data = df.values\n",
    "# split into inpiut and output elements\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 13) (339,)\n",
      "(305, 13) (305,)\n",
      "MAE: 3.356\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on training dataset with outliers removed\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "df = read_csv(url, header=None)\n",
    "# retrieve the array\n",
    "data = df.values\n",
    "# split into inpiut and output elements\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize the shape of the training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "# identify outliers in the training dataset\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "# select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "# summarize the shape of the updated training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong>Comentarios sobre el ejercicio</strong>\n",
    "\n",
    "En este ejercicio se cubrió el concepto de \t`outlier`, el cual hace referencia a aquellos datos que se encuentran por fuera del rango o grupo de observaciones normales para un conjunto de datos. Esto lleva a la necesidad de utilizar técnicas estadísticas para tratar con datos tanto normalizados como los que necesitan ser pasados por este proceso. \n",
    "\n",
    "### Técnicas utilizadas\n",
    "\n",
    "1. Método de la desviación estándar\n",
    "\t- Permite encontrar los outliers por medio del análisis de la desviación estándar de la media, aunque para que este método funcione debe utilizarse un conjunto con un comportamiento similar al de la distribución gausseana.\n",
    "\n",
    "<br>\n",
    "\n",
    "2. Rango intercuartílico\n",
    "\t- Mediante la diferencia de los percentiles 75 y 25, se puede encontrar cuál es el cuerpo del conjunto de datos, pues este rango hace referencia al 50% o la mitad del conjunto. Los outliers son aquellos que caen afuera de los rangos establecidos.\n",
    "\n",
    "<br>\n",
    "\n",
    "3. Detección automática de outliers\n",
    "\t- Utiliza algoritmos de aprendizaje de máquina en los cuales se alimenta un modelo con un set de datos previamente clasificados como 'normales'. Al tener estos datos de entrenamiento, se pueden clasificar las nuevas entradas como normales, outliers o anomalías.\n",
    "\n",
    "\n",
    "Al igual que en las prácticas anteriores, este proceso es necesario para iniciar el análisis de los datos. Como hemos hablado en clase, es muy probable que el proceso de análisis termine dando un resultado, pero la calidad, veracidad y utilidad de este dependerá tanto de una buena elección de métodos para su tratamiento y preparación como para su análisis. Me imagino que técnicas como esta se utilizan mucho en las grandes empresas que cuentan con almacenes de datos y necesitan hacer un análisis para presentarlo a la gerencia y que sea de utilidad para la toma de decisiones."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d84c614dc5133cfe8afdd35cd0e89d9e7c494d88a4d58a2a5280097bf69d7348"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

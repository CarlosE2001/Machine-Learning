{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Universidad de Costa Rica <br>Escuela de Ciencias de la Computación e Informática <br>Análisis de Grandes Volúmenes de Datos <br>Carlos Espinoza B92786**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction on Tabular Data For Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13) (178,)\n"
     ]
    }
   ],
   "source": [
    "# example of loading and summarizing the wine dataset\n",
    "from pandas import read_csv\n",
    "# define the location of the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
    "# load the dataset as a data frame\n",
    "df = read_csv(url, header=None)\n",
    "# retrieve the numpy array\n",
    "data = df.values\n",
    "# split the columns into input and output variables\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# summarize the shape of the loaded data\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953 (0.048)\n"
     ]
    }
   ],
   "source": [
    "# baseline model performance on the wine dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
    "df = read_csv(url, header=None)\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# minimally prepare dataset\n",
    "X = X.astype('float')\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))\n",
    "# define the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# define the cross-validation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.968 (0.037)\n"
     ]
    }
   ],
   "source": [
    "# data preparation as feature engineering for wine dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
    "df = read_csv(url, header=None)\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# minimally prepare dataset\n",
    "X = X.astype('float')\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))\n",
    "# transforms for the feature union\n",
    "transforms = list()\n",
    "transforms.append(('mms', MinMaxScaler()))\n",
    "transforms.append(('ss', StandardScaler()))\n",
    "transforms.append(('rs', RobustScaler()))\n",
    "transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n",
    "transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n",
    "transforms.append(('pca', PCA(n_components=7)))\n",
    "transforms.append(('svd', TruncatedSVD(n_components=7)))\n",
    "# create the feature union\n",
    "fu = FeatureUnion(transforms)\n",
    "# define the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# define the pipeline\n",
    "steps = list()\n",
    "steps.append(('fu', fu))\n",
    "steps.append(('m', model))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# define the cross-validation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.989 (0.022)\n"
     ]
    }
   ],
   "source": [
    "# data preparation as feature engineering with feature selection for wine dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
    "df = read_csv(url, header=None)\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# minimally prepare dataset\n",
    "X = X.astype('float')\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))\n",
    "# transforms for the feature union\n",
    "transforms = list()\n",
    "transforms.append(('mms', MinMaxScaler()))\n",
    "transforms.append(('ss', StandardScaler()))\n",
    "transforms.append(('rs', RobustScaler()))\n",
    "transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n",
    "transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n",
    "transforms.append(('pca', PCA(n_components=7)))\n",
    "transforms.append(('svd', TruncatedSVD(n_components=7)))\n",
    "# create the feature union\n",
    "fu = FeatureUnion(transforms)\n",
    "# define the feature selection\n",
    "rfe = RFE(estimator=LogisticRegression(solver='liblinear'), n_features_to_select=15)\n",
    "# define the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# define the pipeline\n",
    "steps = list()\n",
    "steps.append(('fu', fu))\n",
    "steps.append(('rfe', rfe))\n",
    "steps.append(('m', model))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# define the cross-validation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comentarios\n",
    "\n",
    "Como se pudo ver en la explicación en la clase, es importante ser conscientes del trabajo que realizamos. En ocasiones un par de pruebas pueden tirar resultados positivos pero que no son verídicos, pues da la casualidad que al correr las pruebas, estas aleatoriamente utilizaron los datos que tiraban los mejores resultados y la mayor \"confianza\", mientras que al utilizar más muestras, podemos ver como ese número cambia."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d84c614dc5133cfe8afdd35cd0e89d9e7c494d88a4d58a2a5280097bf69d7348"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
